import pandas as pd;
import nltk,spacy,re,emoji,pyLDAvis,requests,gensim,pyLDAvis,nerer,datetime,twitter,random,bs4,PIL,numpy,polyglot;
from  nltk.tokenize import word_tokenize;
from nltk.corpus import stopwords;
from wordcloud import WordCloud,STOPWORDS;
import matplotlib.pyplot as plt;
import seaborn as sns;
from gensim import models,corpora;
from polyglot.text import Text, Word;
import pyLDAvis.gensim;
from time import time;
from geopy.geocoders import Nominatim;
from geopy.extra.rate_limiter import RateLimiter;
from matplotlib import style;
from sklearn.model_selection import train_test_split;
from sklearn.feature_extraction.text import TfidfVectorizer;
from sklearn.linear_model import LogisticRegression;
from sklearn.metrics import *;
from sklearn.ensemble import RandomForestClassifier;
from sklearn.tree import DecisionTreeClassifier;
from sklearn.feature_extraction.text import CountVectorizer;
from sklearn import svm;
from warnings import simplefilter;
from sklearn.model_selection import GridSearchCV;
from sklearn.exceptions import ConvergenceWarning;
from nltk.corpus import sentiwordnet as swn;
from gensim.models import Word2Vec;
from tensorflow.keras.layers import Embedding;
from tensorflow.keras.preprocessing.sequence import pad_sequences;
from tensorflow.keras.models import Sequential;
from tensorflow.keras.preprocessing.text import one_hot;
from tensorflow.keras.layers import LSTM;
from tensorflow.keras.layers import Dense;
from tensorflow.keras.layers import Bidirectional;
from tensorflow.keras.layers import Dropout;
try: from twitter_creds import *
except: pass;