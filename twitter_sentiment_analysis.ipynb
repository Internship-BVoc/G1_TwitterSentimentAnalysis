{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter_sentiment_analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNsC2Z6duq5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "df823df3-eef5-4ad7-b29e-dde8fba1942a"
      },
      "source": [
        "import pandas as pd \n",
        "import nltk,spacy,re\n",
        "from  nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from bs4 import BeautifulSoup\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df = pd.read_csv('Tweets-A.csv')\n",
        "df.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>name</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.703060e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24/02/15 11:35</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>positive</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24/02/15 11:15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24/02/15 11:15</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24/02/15 11:15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24/02/15 11:14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       tweet_id airline_sentiment  ... tweet_location               user_timezone\n",
              "0  5.703060e+17           neutral  ...            NaN  Eastern Time (US & Canada)\n",
              "1  5.703010e+17          positive  ...            NaN  Pacific Time (US & Canada)\n",
              "2  5.703010e+17           neutral  ...      Lets Play  Central Time (US & Canada)\n",
              "3  5.703010e+17          negative  ...            NaN  Pacific Time (US & Canada)\n",
              "4  5.703010e+17          negative  ...            NaN  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5FOZ85QmreA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TweetId is primary key.......Tweet_cord has more than 80% of missing rows so dropped it\n",
        "df_data = df.copy()\n",
        "df_data.drop(columns=['tweet_id','tweet_coord'],inplace=True)\n",
        "\n",
        "#Column ['Text'] pre-processing by converting it to lower case\n",
        "df_data.text = df_data.text.apply(lambda text:text.lower() if type(text) == str else text)\n",
        "\n",
        "#HREF Links Removal\n",
        "df_data.text = df_data.text.apply(lambda text: re.compile(r'https?://\\S+|www\\.\\S+').sub(r'',text))\n",
        "\n",
        "#HTML Text Removal\n",
        "df_data.text = df_data.text.apply(lambda text: BeautifulSoup(text,'html.parser').text)\n",
        "\n",
        "#HashTags Separation And Merging\n",
        "df_data['hashtags'] = [ [ tag[1: ] for tag in i.split() if tag.startswith('#') ] for i in df_data.text ]\n",
        "\n",
        "#@Entities Separation And Merging\n",
        "df_data['tags'] = [ [ ent[1: ] for ent in i.split() if ent.startswith(\"@\") ] for i in df_data.text ]\n",
        "\n",
        "#Punctuations Removal\n",
        "df_data.text = df_data.text.str.replace('[^\\w\\s]','')\n",
        "\n",
        "#StopWords Removal\n",
        "df_data.text = [ \" \".join(([word for word in word_tokenize(i) if not word in list((stopwords.words('english')))]))  for i in df_data.text ]\n",
        "\n",
        "#Lemmatization - Aiming to remove inflectional endings and return the base meaning or dictionary meaning of a word also known as lemma\n",
        "df_data.text = df_data.text.apply(lambda text: lemmatizer.lemmatize(text))"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcDWzjFtjfft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "df_data.to_csv(str(int(time()))+'_Update1.csv')"
      ],
      "execution_count": 65,
      "outputs": []
    }
  ]
}